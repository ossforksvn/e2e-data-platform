{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caff0a1b-3ecb-405a-872c-07ae3040b571",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "    .appName('local')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9657d1c-dc6c-4f0d-a44b-04ff7559de06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CatalogMetadata(name='iceberg', description=None),\n",
       " CatalogMetadata(name='spark_catalog', description=None)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listCatalogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeb29e9c-015c-4163-bbb6-b38a3f1bb956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.sql.catalog.spark_catalog',\n",
       "  'org.apache.iceberg.spark.SparkSessionCatalog'),\n",
       " ('spark.sql.catalog.iceberg.uri', 'thrift://hive-metastore:9083'),\n",
       " ('spark.sql.catalog.iceberg.s3.endpoint', 'http://minio:9000'),\n",
       " ('spark.sql.catalog.iceberg.s3.path-style-access', 'true'),\n",
       " ('spark.sql.catalog.iceberg.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO'),\n",
       " ('spark.sql.catalog.iceberg.warehouse', 's3a:/iceberg'),\n",
       " ('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog'),\n",
       " ('spark.sql.catalog.iceberg.type', 'hive'),\n",
       " ('spark.sql.catalog.spark_catalog.type', 'hive')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all configs\n",
    "spark.sparkContext.getConf().getAll()\n",
    "\n",
    "# Or filter by catalog configs\n",
    "[k for k in spark.sparkContext.getConf().getAll() if k[0].startswith(\"spark.sql.catalog.\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3dd75b8-01aa-478e-976d-8bd2daa29b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|      iceberg|\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|      raw|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()\n",
    "spark.sql(\"SHOW DATABASES IN iceberg\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "401031cd-1beb-4d7e-9147-48a7a8bd1688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all tables in the namespace\n",
    "tables = spark.catalog.listTables(\"iceberg.raw\")\n",
    "\n",
    "# Drop each table\n",
    "for t in tables:\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS iceberg.raw.{t.name}\")\n",
    "\n",
    "# Now drop the namespace (database)\n",
    "spark.sql(\"DROP DATABASE IF EXISTS iceberg.raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4efcffd-dc42-43b4-93c6-053aadc16ee2",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP DATABASE IF EXISTS iceberg.raw CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e28f5039-f246-417b-8670-b84c1abed436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS iceberg.raw COMMENT '' LOCATION 's3a://iceberg/raw/'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "772be00b-9223-46c2-a927-6e967ad4da78",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS iceberg.raw.sample (\n",
    "        id bigint,\n",
    "        data string,\n",
    "        category string,\n",
    "        ts timestamp)\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (bucket(16, id), days(ts), category)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ca88ab7-9350-4a65-bec7-1ca13f006a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                        |comment|\n",
      "+----------------------------+-------------------------------------------------+-------+\n",
      "|id                          |bigint                                           |null   |\n",
      "|data                        |string                                           |null   |\n",
      "|category                    |string                                           |null   |\n",
      "|ts                          |timestamp                                        |null   |\n",
      "|                            |                                                 |       |\n",
      "|# Partitioning              |                                                 |       |\n",
      "|Part 0                      |bucket(16, id)                                   |       |\n",
      "|Part 1                      |days(ts)                                         |       |\n",
      "|Part 2                      |category                                         |       |\n",
      "|                            |                                                 |       |\n",
      "|# Metadata Columns          |                                                 |       |\n",
      "|_spec_id                    |int                                              |       |\n",
      "|_partition                  |struct<id_bucket:int,ts_day:date,category:string>|       |\n",
      "|_file                       |string                                           |       |\n",
      "|_pos                        |bigint                                           |       |\n",
      "|_deleted                    |boolean                                          |       |\n",
      "|                            |                                                 |       |\n",
      "|# Detailed Table Information|                                                 |       |\n",
      "|Name                        |iceberg.raw.sample                               |       |\n",
      "|Type                        |MANAGED                                          |       |\n",
      "+----------------------------+-------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"DESCRIBE NAMESPACE iceberg.raw\")\n",
    "# spark.sql(\"DESCRIBE DATABASE iceberg.raw\").show(truncate=False)\n",
    "spark.sql(\"DESCRIBE FORMATTED iceberg.raw.sample\").show(truncate=False)\n",
    "# spark.table(\"iceberg.raw.sample\").inputFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff13884-ff88-43a5-a42b-1fc91a95889b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    INSERT INTO iceberg.raw.sample VALUES\n",
    "        (1, 'a', 'cat1', TIMESTAMP '2023-01-01 10:00:00'),\n",
    "        (2, 'b', 'cat2', TIMESTAMP '2023-01-02 12:00:00'),\n",
    "        (3, 'c', 'cat1', TIMESTAMP '2023-01-03 14:30:00'),\n",
    "        (4, 'd', 'cat3', TIMESTAMP '2023-01-04 09:15:00'),\n",
    "        (5, 'e', 'cat2', TIMESTAMP '2023-01-05 16:45:00')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d406540e-8306-48fa-8230-7865a0728401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-------------------+\n",
      "| id|data|category|                 ts|\n",
      "+---+----+--------+-------------------+\n",
      "|  3|   c|    cat1|2023-01-03 14:30:00|\n",
      "|  1|   a|    cat1|2023-01-01 10:00:00|\n",
      "|  2|   b|    cat2|2023-01-02 12:00:00|\n",
      "|  4|   d|    cat3|2023-01-04 09:15:00|\n",
      "|  3|   c|    cat1|2023-01-03 14:30:00|\n",
      "|  5|   e|    cat2|2023-01-05 16:45:00|\n",
      "|  1|   a|    cat1|2023-01-01 10:00:00|\n",
      "|  2|   b|    cat2|2023-01-02 12:00:00|\n",
      "|  4|   d|    cat3|2023-01-04 09:15:00|\n",
      "|  5|   e|    cat2|2023-01-05 16:45:00|\n",
      "+---+----+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM raw.sample\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ba2c37d-80d2-4a4c-9ac3-25253c6459be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-------------------+\n",
      "| id|data|category|                 ts|\n",
      "+---+----+--------+-------------------+\n",
      "|  3|   c|    cat1|2023-01-03 14:30:00|\n",
      "|  3|   c|    cat1|2023-01-03 14:30:00|\n",
      "|  1|   a|    cat1|2023-01-01 10:00:00|\n",
      "|  1|   a|    cat1|2023-01-01 10:00:00|\n",
      "|  2|   b|    cat2|2023-01-02 12:00:00|\n",
      "|  2|   b|    cat2|2023-01-02 12:00:00|\n",
      "|  4|   d|    cat3|2023-01-04 09:15:00|\n",
      "|  4|   d|    cat3|2023-01-04 09:15:00|\n",
      "|  5|   e|    cat2|2023-01-05 16:45:00|\n",
      "|  5|   e|    cat2|2023-01-05 16:45:00|\n",
      "+---+----+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM iceberg.raw.sample\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
